# AI í•™ìŠµ/ì—°êµ¬ ë©”ëª¨ ìš”ì•½ê¸°
# ê¸°ëŠ¥: ì‚¬ìš©ìê°€ ê¸´ ê¸€(ë…¼ë¬¸ ì´ˆë¡, ë¸”ë¡œê·¸ ê¸€, ìˆ˜ì—… í•„ê¸°)ì„ ì…ë ¥ â†’ LLaMA ëª¨ë¸ë¡œ í•µì‹¬ ìš”ì•½
# ê²°ê³¼: Gradio UIì—ì„œ "ì›ë¬¸ / ìš”ì•½ íƒ­ìœ¼ë¡œ ë³´ê¸°

# -*- coding: utf-8 -*-
import gradio as gr
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# =========================
# 1) ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ìš”ì•½)
# =========================
summarizer_model_name = "lcw99/t5-base-korean-text-summary"
summarizer_tokenizer = AutoTokenizer.from_pretrained(summarizer_model_name)
summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(summarizer_model_name)

# =========================
# 2) ìš”ì•½ í•¨ìˆ˜
# =========================
def summarize_text(text, length_option="ë³´í†µ"):
    text = text.strip()
    
    # ì§§ì€ ê¸€ ì˜ˆì™¸ ì²˜ë¦¬
    if len(text) < 100:
        return text
    
    if length_option == "ì§§ê²Œ":
        max_len, min_len = 80, 30
    else:  # ë³´í†µ
        max_len, min_len = 200, 50
    
    inputs = summarizer_tokenizer(
        text, 
        return_tensors="pt", 
        max_length=1024, 
        truncation=True
    )
    summary_ids = summarizer_model.generate(
        inputs['input_ids'], 
        max_length=max_len, 
        min_length=min_len, 
        num_beams=4, 
        early_stopping=True,
        no_repeat_ngram_size=3
    )
    summary = summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

def summarize_and_process(text, length_option):
    text = text.strip()
    original_len = len(text)
    
    if not text:
        return "ì›ë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.", ""
    
    summary = summarize_text(text, length_option)
    summary_len = len(summary)
    
    out_original = f"{text}\n\n(ì´ ê¸€ììˆ˜: {original_len})"
    out_summary = f"{summary}\n\n(ì´ ê¸€ììˆ˜: {summary_len})"
    
    return out_original, out_summary

# =========================
# 3) Gradio UI
# =========================
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ“ í•œêµ­ì–´ AI ìš”ì•½ (ì˜ˆì‹œ ê¸€ ì…ë ¥í•´ë†¨ìŒ)")

    inp = gr.Textbox(
        lines=12, 
        placeholder="ì—¬ê¸°ì— í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”. 100ê¸€ì ì´ìƒ", 
        label="ì›ë¬¸ ì…ë ¥",
        value="""íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ 2017ë…„ì— ì†Œê°œëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œ, ìì—°ì–´ ì²˜ë¦¬ì—ì„œ í° í˜ì‹ ì„ ê°€ì ¸ì™”ë‹¤.  
ì´ ëª¨ë¸ì€ ì…€í”„ ì–´í…ì…˜(Self-Attention) ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ ì‹œí€€ìŠ¤ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤.  
ê¸°ì¡´ì˜ RNNê³¼ ë‹¬ë¦¬ ì¥ê¸° ì˜ì¡´ì„± ë¬¸ì œë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆì–´ ë²ˆì—­, ìš”ì•½, ì§ˆë¬¸ì‘ë‹µ ë“± ë‹¤ì–‘í•œ NLP íƒœìŠ¤í¬ì—ì„œ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤.  
íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ì˜ ëª¨ë¸ë“¤ì€ ì´í›„ BERT, GPT, T5 ë“± ì—¬ëŸ¬ íŒŒìƒ ëª¨ë¸ì˜ ê¸°ì´ˆê°€ ë˜ì—ˆìœ¼ë©°, í˜„ì¬ ìì—°ì–´ ì²˜ë¦¬ ì—°êµ¬ì—ì„œ í‘œì¤€ìœ¼ë¡œ ìë¦¬ ì¡ì•˜ë‹¤.  
ì´ëŸ¬í•œ ë°œì „ ë•ë¶„ì— ì±—ë´‡, ê¸°ê³„ë²ˆì—­, ìë™ ìš”ì•½ ë“± ì‹¤ì œ ì„œë¹„ìŠ¤ì— ë°”ë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¤€ê¹Œì§€ ë„ë‹¬í•˜ì˜€ë‹¤."""
    )
    
    length_option = gr.Radio(["ì§§ê²Œ", "ë³´í†µ"], label="ìš”ì•½ ê¸¸ì´ ì„ íƒ", value="ë³´í†µ")
    btn = gr.Button("ì‹¤í–‰")

    with gr.Tabs():
        with gr.Tab("ì›ë¬¸"):
            out_original = gr.Textbox(label="ì›ë¬¸ + ê¸€ììˆ˜", lines=8)
        with gr.Tab("ìš”ì•½"):
            out_summary = gr.Textbox(label="ìš”ì•½ + ê¸€ììˆ˜", lines=8)

    btn.click(
        summarize_and_process,
        inputs=[inp, length_option],
        outputs=[out_original, out_summary]
    )

# =========================
# 4) ì‹¤í–‰
# =========================
if __name__ == "__main__":
    demo.launch(share=True)
 